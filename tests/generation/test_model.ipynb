{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T10:01:18.680825Z",
     "start_time": "2024-10-01T10:01:14.269776Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 12:03:19.208536: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-01 12:03:19.223945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-01 12:03:19.241418: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-01 12:03:19.246784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-01 12:03:19.260898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-01 12:03:20.076198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ProtMamba_ssm.core import *\n",
    "from ProtMamba_ssm.dataloaders import *\n",
    "from ProtMamba_ssm.utils import *\n",
    "from ProtMamba_ssm.modules import *\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T10:01:19.204208Z",
     "start_time": "2024-10-01T10:01:19.182142Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def smooth(scalars: list[float], weight: float) -> list[float]:\n",
    "    \"\"\"\n",
    "    Exponential moving average\n",
    "    \"\"\"\n",
    "    last = 0\n",
    "    smoothed = []\n",
    "    num_acc = 0\n",
    "    for next_val in scalars:\n",
    "        last = last * weight + (1 - weight) * next_val\n",
    "        num_acc += 1\n",
    "        # de-bias\n",
    "        debias_weight = 1\n",
    "        if weight != 1:\n",
    "            debias_weight = 1 - math.pow(weight, num_acc)\n",
    "        smoothed_val = last / debias_weight\n",
    "        smoothed.append(smoothed_val)\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "def find_fim_indices(is_cls_tokens, is_eos_tokens):\n",
    "    # add a cls token at the beginning\n",
    "    is_cls_tokens = torch.cat([torch.ones_like(is_cls_tokens[:, :1]), is_cls_tokens], dim=1)\n",
    "    is_eos_tokens = torch.cat([torch.zeros_like(is_eos_tokens[:, :1]), is_eos_tokens], dim=1)\n",
    "    # both eos and cls tokens\n",
    "    bol = is_cls_tokens | is_eos_tokens\n",
    "    tmp = torch.zeros_like(is_cls_tokens, dtype=torch.int)\n",
    "    tmp[torch.nonzero(is_cls_tokens, as_tuple=True)] = 1\n",
    "    tmp[torch.nonzero(is_eos_tokens, as_tuple=True)] = -1\n",
    "    bol1 = torch.clone(bol)\n",
    "    for batch_ind in range(tmp.size(0)):\n",
    "        tmp1 = tmp[batch_ind,bol[batch_ind]]\n",
    "        # find all positions where a 1 if preceeded by a -1\n",
    "        tmp1 = tmp1[:-1]*tmp1[1:]\n",
    "        # add the first element to make the sequence start with a 1\n",
    "        tmp1 = torch.cat([torch.ones_like(tmp1[:1]).to(tmp1.device), tmp1])\n",
    "        new_bol = tmp1<0\n",
    "        # bool array True only in the positions where a 1 is preceeded by a -1\n",
    "        bol1[batch_ind,bol[batch_ind]] = False if new_bol.size(0) == 0 else new_bol\n",
    "    cumulative_sum = torch.cumsum(bol1, dim=1)\n",
    "    # Use modulo operation to get the desired tensor\n",
    "    bol2 = cumulative_sum % 2 == 1\n",
    "    bol2[is_eos_tokens]= False\n",
    "    return bol2[:,1:]\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, labels, full_fim=False):\n",
    "    predictions = predictions.permute(0, 2, 1)\n",
    "    labels = labels\n",
    "    # shift labels to align them with predictions and remove last prediction to match the length\n",
    "    predictions = predictions[:, :, :-1].contiguous()\n",
    "    labels = labels[:, 1:].contiguous()\n",
    "    # compute unreduced elementwise loss\n",
    "    unreduced_loss = torch.nn.functional.cross_entropy(predictions, labels, reduction=\"none\")\n",
    "    # compute reconstruction accuracy\n",
    "    reconstruction = (predictions.argmax(1) == labels)\n",
    "\n",
    "    # start and end tokens\n",
    "    is_cls_tokens = (labels == AA_TO_ID[\"<cls>\"])\n",
    "    is_eos_tokens = (labels == AA_TO_ID[\"<eos>\"])\n",
    "    # fill in the middle tokens\n",
    "    if full_fim:\n",
    "        print(\"Using for loop fim\")\n",
    "        fim_tokens = torch.zeros(is_cls_tokens.size(0), is_cls_tokens.size(1), dtype=torch.bool).to(is_cls_tokens.device)\n",
    "        in_mask_vector = torch.zeros(is_cls_tokens.size(0), dtype=torch.bool).to(is_cls_tokens.device)\n",
    "        for j in range(is_cls_tokens.size(1)):\n",
    "            in_mask_vector = in_mask_vector & ~is_cls_tokens[:, j]\n",
    "            fim_tokens[:, j] = in_mask_vector\n",
    "            in_mask_vector = in_mask_vector | is_eos_tokens[:, j]\n",
    "    else:\n",
    "        fim_tokens = find_fim_indices(is_cls_tokens, is_eos_tokens)\n",
    "\n",
    "    number_sequences = torch.cumsum(torch.cat([torch.zeros(is_cls_tokens.size(0),1, dtype=torch.int32).to(is_cls_tokens.device), is_cls_tokens[:,:-1]],1), -1)\n",
    "    # sequence tokens\n",
    "    sequence_perplexity, sequence_fim_perplexity = [], []\n",
    "    sequence_loss, sequence_fim_loss = [], []\n",
    "    sequence_size_fim_part = []\n",
    "    num_tokens_preceeding = []\n",
    "    num_tokens = torch.arange(labels.size(1)).to(labels.device)\n",
    "    num_tokens = torch.cat([num_tokens[None, :] for _ in range(labels.size(0))], dim=0)\n",
    "    for i in range(torch.max(number_sequences.max(1).values[:, None] - 1).item()):\n",
    "        i_sequence_tokens = ((~fim_tokens & (labels < 33)) | fim_tokens) & (number_sequences == i)\n",
    "        i_sequence_tokens_fim = fim_tokens & (number_sequences == i) \n",
    "        i_sequence_cls_tokens = is_cls_tokens & (number_sequences == i)\n",
    "        num_tokens_preceeding.append(num_tokens[i_sequence_cls_tokens])\n",
    "        sequence_perplexity.append(torch.exp(torch.mean(unreduced_loss[i_sequence_tokens])).item())\n",
    "        sequence_fim_perplexity.append(torch.exp(torch.mean(unreduced_loss[i_sequence_tokens_fim])).item())\n",
    "        sequence_loss.append(torch.mean(unreduced_loss[i_sequence_tokens]).item())\n",
    "        sequence_fim_loss.append(torch.mean(unreduced_loss[i_sequence_tokens_fim]).item())\n",
    "        tmp1 = i_sequence_tokens_fim & (labels < 33)\n",
    "        tmp2 = i_sequence_tokens_fim & (labels >= 33)\n",
    "        sequence_size_fim_part.append((tmp1.sum()/tmp2.sum()).item())\n",
    "    # metrics\n",
    "    # cum_loss = torch.cumsum(unreduced_loss, dim=1)/torch.cumsum(torch.ones_like(unreduced_loss), dim=1)\n",
    "    return {\"loss\": unreduced_loss,\n",
    "            \"sequence_losses\": torch.tensor(sequence_loss),\n",
    "            \"sequence_perplexities\": torch.tensor(sequence_perplexity),\n",
    "            \"sequence_fim_losses\": torch.tensor(sequence_fim_loss),\n",
    "            \"sequence_fim_perplexities\": torch.tensor(sequence_fim_perplexity),\n",
    "            \"sequence_size_fim_part\": torch.tensor(sequence_size_fim_part),\n",
    "            \"reconstruction\": reconstruction,\n",
    "            \"num_tokens_preceeding\": torch.tensor(num_tokens_preceeding),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T10:02:01.875669Z",
     "start_time": "2024-10-01T10:02:01.843837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a model that was pretrained with gradient checkpointing but now do not want to use it. Changed the keys of the state_dict to match the model's keys.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MambaLMHeadModelwithPosids(\n",
       "  (backbone): MixerModelWithPosids(\n",
       "    (embedding): Embedding(40, 512)\n",
       "    (position_embedding): Embedding(2048, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x Block(\n",
       "        (norm): RMSNorm()\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=2048, out_features=96, bias=False)\n",
       "          (dt_proj): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=40, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_fim = True\n",
    "dataset_name = \"encoded_MSAs_test.pkl\"\n",
    "fim_strategy = \"multiple_span\" if is_fim else \"no-scramble\"\n",
    "# Load dataset\n",
    "dataset = Uniclust30_Dataset(dataset_name,\n",
    "                             filepath=\"/nvme1/common/OpenProteinSet/\",\n",
    "                             max_msa_len=135000,\n",
    "                             sample=False,\n",
    "                             max_patches=1,\n",
    "                             mask_fraction=0.1,\n",
    "                             fim_strategy=fim_strategy,\n",
    "                             max_position_embeddings=2048,\n",
    "                             add_position_ids=\"1d\")\n",
    "device = \"cuda\"\n",
    "# Load pretrained model\n",
    "model = load_model(\"/nvme1/common/mamba_100M_FIM-finetuned_131k_checkpoint-3200\",\n",
    "                   model_class=MambaLMHeadModelwithPosids,\n",
    "                   device=device,\n",
    "                   dtype=torch.bfloat16,\n",
    "                   checkpoint_mixer=False)\n",
    "model.eval()\n",
    "# model = torch.compile(model)\n",
    "# data_collator = DataCollatorForUniclust30Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of length sequences in dataset\n",
    "lengths = []\n",
    "for i in range(len(dataset)):\n",
    "    data = dataset[i][\"input_ids\"]\n",
    "    start = dataset.get_index_start_of_sequences(dataset[i][\"input_ids\"])\n",
    "    lengths.append(np.mean(start[1:] - start[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How should the files be named?: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [07:43<21:19:51, 154.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2924552/111252208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# reconstruction += [metrics[\"reconstruction\"].cpu().to(torch.float).numpy()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2924552/4270556209.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(predictions, labels, full_fim)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0msequence_perplexity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munreduced_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sequence_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0msequence_fim_perplexity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munreduced_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sequence_tokens_fim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msequence_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munreduced_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sequence_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0msequence_fim_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munreduced_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sequence_tokens_fim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_sequence_tokens_fim\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "what = input(\"How should the files be named?:\") # \"0.05-135k_new\"\n",
    "loss = []\n",
    "# reconstruction = []\n",
    "seq_size_fim_part = []\n",
    "seq_loss, seq_perp = [], []\n",
    "seq_fim_loss, seq_fim_perp = [], []\n",
    "num_tokens_preceeding = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        for j in range(100):\n",
    "            data = dataset[i]#data_collator([dataset[i] for j in range(4)])\n",
    "            tokens = data[\"input_ids\"][None,:].to(device)\n",
    "            pos_ids = data[\"position_ids\"][None,:].to(device)\n",
    "            # tokens = data[\"input_ids\"].to(device)\n",
    "            # pos_ids = data[\"position_ids\"].to(device)\n",
    "            out = model(tokens, pos_ids)\n",
    "            logits = out.logits\n",
    "            metrics = compute_metrics(logits, tokens)\n",
    "            loss += [metrics[\"loss\"].cpu().to(torch.float).numpy()]\n",
    "            # reconstruction += [metrics[\"reconstruction\"].cpu().to(torch.float).numpy()]\n",
    "            # cum_loss += [metrics[\"cumulative_loss\"][0].cpu().to(torch.float).numpy()]\n",
    "            # cum_perp += [metrics[\"cumulative_perplexity\"][0].cpu().to(torch.float).numpy()]\n",
    "            # cum_rec += [metrics[\"cumulative_reconstruction\"][0].cpu().to(torch.float).numpy()]\n",
    "            seq_loss.append(metrics[\"sequence_losses\"])\n",
    "            seq_perp.append(metrics[\"sequence_perplexities\"])\n",
    "            seq_fim_loss.append(metrics[\"sequence_fim_losses\"])\n",
    "            seq_fim_perp.append(metrics[\"sequence_fim_perplexities\"])\n",
    "            seq_size_fim_part.append(metrics[\"sequence_size_fim_part\"])\n",
    "            num_tokens_preceeding.append(metrics[\"num_tokens_preceeding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[  2.0312,  -1.0234,  -6.9375,  ..., -13.2500, -10.5000,  22.8750]],\n",
       "       device='cuda:0', dtype=torch.bfloat16),\n",
       "indices=tensor([[20,  4,  4,  ...,  8,  2, 33]], device='cuda:0'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor([[2.6562, 3.0156, 2.8125,  ..., 0.2871, 1.7266, 1.1641]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'sequence_losses': tensor([2.2656, 2.2500, 2.0469,  ..., 2.2188, 2.7188, 1.8828]),\n",
       " 'sequence_perplexities': tensor([ 9.6250,  9.5000,  7.7500,  ...,  9.1875, 15.1875,  6.5625]),\n",
       " 'sequence_fim_losses': tensor([   nan,    nan,    nan,  ..., 1.4688, 1.6094, 1.0781]),\n",
       " 'sequence_fim_perplexities': tensor([   nan,    nan,    nan,  ..., 4.3438, 5.0000, 2.9375]),\n",
       " 'sequence_size_fim_part': tensor([nan, nan, nan,  ..., 5., 1., 1.]),\n",
       " 'reconstruction': tensor([[False, False, False,  ...,  True,  True,  True]], device='cuda:0'),\n",
       " 'num_tokens_preceeding': tensor([    94,    176,    297,  ..., 134532, 134734, 134806])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13, 106],\n",
       "        [ 14, 107],\n",
       "        [ 22, 108],\n",
       "        [ 19, 109],\n",
       "        [ 18, 110],\n",
       "        [  4, 111],\n",
       "        [  5, 112],\n",
       "        [ 20, 113],\n",
       "        [  5, 114],\n",
       "        [  2,   0],\n",
       "        [ 33,  27],\n",
       "        [  8,  27],\n",
       "        [ 10,  28],\n",
       "        [ 12,  29],\n",
       "        [  0,   0],\n",
       "        [  5,   1],\n",
       "        [ 22,   2],\n",
       "        [ 10,   3],\n",
       "        [ 11,   4],\n",
       "        [  4,   5]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([tokens[0, idx-10: idx+10], pos_ids[0, idx-10: idx+10]], 0).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_seq_loss, dict_seq_perp = {}, {}\n",
    "dict_seq_length, dict_seq_fim_length = {}, {}\n",
    "dict_seq_fim_loss, dict_seq_fim_perp = {}, {}\n",
    "dict_size_fim = {}\n",
    "ctx_lengths = [1024,2048,4096,8192,16384,32768,65536,131072,262144]\n",
    "dict_ctx_perp, dict_ctx_fim_perp = {l_ctx: [] for l_ctx in ctx_lengths}, {l_ctx: [] for l_ctx in ctx_lengths}\n",
    "dict_ctx_lenghts = {l_ctx: [] for l_ctx in ctx_lengths}\n",
    "dict_ctx_len, dict_ctx_fim_len = {l_ctx: [] for l_ctx in ctx_lengths}, {l_ctx: [] for l_ctx in ctx_lengths}\n",
    "for el in zip(seq_loss, seq_perp, seq_fim_loss, seq_fim_perp, seq_size_fim_part, num_tokens_preceeding):\n",
    "    avg_l = (el[5][-1]/len(el[5])).item()\n",
    "    for i in range(len(el[0])):\n",
    "        if i in dict_seq_loss:\n",
    "            dict_seq_loss[i].append(el[0][i].item())\n",
    "            dict_seq_perp[i].append(el[1][i].item())\n",
    "            dict_seq_length[i].append(avg_l)\n",
    "        else:\n",
    "            dict_seq_perp[i] = [el[1][i].item()]\n",
    "            dict_seq_loss[i] = [el[0][i].item()]\n",
    "            dict_seq_length[i] = [avg_l]\n",
    "    for i in range(len(el[2])):\n",
    "        if i in dict_seq_fim_loss:\n",
    "            if el[2][i] >0:\n",
    "                dict_seq_fim_loss[i].append(el[2][i].item())\n",
    "                dict_seq_fim_length[i].append(avg_l)\n",
    "            if el[3][i]  >0:\n",
    "                dict_seq_fim_perp[i].append(el[3][i].item())\n",
    "            if el[4][i] >0:\n",
    "                dict_size_fim[i].append(el[4][i].item())\n",
    "        else:\n",
    "            if el[2][i] >0:\n",
    "                dict_seq_fim_loss[i] = [el[2][i].item()]\n",
    "                dict_seq_fim_length[i] = [avg_l]\n",
    "            if el[3][i] >0:\n",
    "                dict_seq_fim_perp[i] = [el[3][i].item()]\n",
    "            if el[4][i] >0:\n",
    "                dict_size_fim[i] = [el[4][i].item()]\n",
    "    # context legths\n",
    "    for l_ctx in ctx_lengths:\n",
    "        if el[5][-1].item() > l_ctx and el[5][0].item() < l_ctx:\n",
    "            indx = torch.argwhere(el[5]<=l_ctx)[-1]\n",
    "            dict_ctx_lenghts[l_ctx].append(el[5][indx].item())\n",
    "            dict_ctx_perp[l_ctx].append(el[1][indx].item())\n",
    "            dict_ctx_len[l_ctx].append(avg_l)\n",
    "            if el[3][indx] > 0:\n",
    "                dict_ctx_fim_perp[l_ctx].append(el[3][indx].item())\n",
    "                dict_ctx_fim_len[l_ctx].append(avg_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"figures/{what}\", exist_ok=True)\n",
    "\n",
    "with open(f\"figures/{what}/dict_seq_loss_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_loss, f)\n",
    "with open(f\"figures/{what}/dict_seq_perp_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_perp, f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_loss_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_fim_loss, f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_perp_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_fim_perp, f)\n",
    "with open(f\"figures/{what}/dict_size_fim_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_size_fim, f)\n",
    "with open(f\"figures/{what}/dict_ctx_lengths_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_ctx_lenghts, f)\n",
    "with open(f\"figures/{what}/dict_ctx_perp_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_ctx_perp, f)\n",
    "with open(f\"figures/{what}/dict_ctx_fim_perp_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_ctx_fim_perp, f)\n",
    "with open(f\"figures/{what}/dict_seq_length_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_length, f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_length_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_seq_fim_length, f)\n",
    "with open(f\"figures/{what}/dict_ctx_len_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_ctx_len, f)\n",
    "with open(f\"figures/{what}/dict_ctx_fim_len_all_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_ctx_fim_len, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(\n",
    "    context='notebook', style='ticks', palette='bright',\n",
    "    color_codes=True)  #other contexts: “paper”, “talk”, and “poster”,\n",
    "\n",
    "# Plotting settings\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"sans-serif\", #sans-serif\n",
    "    \"font.serif\": [\"Arial\"],\n",
    "    \"font.size\": MEDIUM_SIZE,\n",
    "    \"axes.titlesize\": MEDIUM_SIZE,\n",
    "    \"axes.labelsize\": MEDIUM_SIZE,\n",
    "    \"figure.titlesize\": MEDIUM_SIZE,\n",
    "    \"figure.labelsize\": MEDIUM_SIZE,\n",
    "    \"xtick.labelsize\": SMALL_SIZE,\n",
    "    \"ytick.labelsize\": SMALL_SIZE,\n",
    "    \"legend.fontsize\": MEDIUM_SIZE,\n",
    "})\n",
    "\n",
    "color_ = [(64, 83, 211), (0, 178, 93), (181, 29, 20), (221, 179, 16), (0, 190, 255), (251, 73, 176), (202, 202, 202)]\n",
    "color =[]\n",
    "for t in color_:\n",
    "    color.append(tuple(ti/255 for ti in t))\n",
    "    \n",
    "# split a dictionary based on the length of the sequences\n",
    "def split_lengths(dic, lengths, L=[100, 200]):\n",
    "    new_dic = {ll: {j: [] for j in dic.keys()} for ll in L+[-1]}\n",
    "    for j in dic.keys():\n",
    "        lst = dic[j]\n",
    "        lst_l = lengths[j]\n",
    "        for i in range(len(lst)):\n",
    "            for ll in L:\n",
    "                if lst_l[i] <= ll:\n",
    "                    new_dic[ll][j].append(lst[i])\n",
    "                elif ll == L[-1]:\n",
    "                    new_dic[-1][j].append(lst[i])\n",
    "    return new_dic, L+[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = input(\"Name:\")\n",
    "with open(f\"figures/{what}/dict_seq_loss_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_loss = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_seq_perp_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_perp = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_loss_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_fim_loss = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_perp_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_fim_perp = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_size_fim_all_test.pkl\", \"rb\") as f:\n",
    "    dict_size_fim = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_ctx_lengths_all_test.pkl\", \"rb\") as f:\n",
    "    dict_ctx_lenghts = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_ctx_perp_all_test.pkl\", \"rb\") as f:\n",
    "    dict_ctx_perp = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_ctx_fim_perp_all_test.pkl\", \"rb\") as f:\n",
    "    dict_ctx_fim_perp = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_seq_length_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_length = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_seq_fim_length_all_test.pkl\", \"rb\") as f:\n",
    "    dict_seq_fim_length = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_ctx_len_all_test.pkl\", \"rb\") as f:\n",
    "    dict_ctx_len = pickle.load(f)\n",
    "with open(f\"figures/{what}/dict_ctx_fim_len_all_test.pkl\", \"rb\") as f:\n",
    "    dict_ctx_fim_len = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(20,10), sharex=True, constrained_layout=True)\n",
    "\n",
    "keys = list(dict_seq_perp.keys())\n",
    "vals = [5,25,55,105,155,205,255,505,755,1005]\n",
    "keys = {i: [keys[j-5+vals[i]] for j in range(11)] for i in range(len(vals))}\n",
    "do_fim = True if len(dict_seq_fim_perp) > 0 else False\n",
    "for i, keys_t in enumerate(keys):\n",
    "    all_vals0, all_vals1 = [], []\n",
    "    for key in keys[keys_t]:\n",
    "        all_vals0 += dict_seq_perp[key]\n",
    "        if do_fim:\n",
    "            all_vals1 += dict_seq_fim_perp[key]\n",
    "    axs[i//5,i%5].axvline(np.median(all_vals0), color=color[0], linestyle=\"--\")\n",
    "    axs[i//5,i%5].hist(all_vals0, bins=np.linspace(0,30,40), alpha=0.5, color=color[0], density=True, label=\"full\")\n",
    "    if do_fim:\n",
    "        axs[i//5,i%5].axvline(np.median(all_vals1), color=color[1], linestyle=\"--\")\n",
    "        axs[i//5,i%5].hist(all_vals1, bins=np.linspace(0,30,40), alpha=0.5, color=color[1], density=True, label=\"fim\")\n",
    "    axs[i//5,i%5].set_title(f\"Seq. positions: ({keys[keys_t][0]}-{keys[keys_t][-1]})\")\n",
    "axs[0,0].legend()\n",
    "fig.supxlabel(\"Perplexity\")\n",
    "fig.supylabel(\"Count\")\n",
    "fig.suptitle(\"Perplexity distributions\")\n",
    "fig.savefig(f\"figures/{what}/perplexity_distributions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2,5, figsize=(20,10), sharex=True, constrained_layout=True)\n",
    "for i, keys_t in enumerate(keys):\n",
    "    all_vals0, all_vals1 = [], []\n",
    "    for key in keys[keys_t]:\n",
    "        all_vals0 += dict_seq_loss[key]\n",
    "        if do_fim:\n",
    "            all_vals1 += dict_seq_fim_loss[key]\n",
    "    axs[i//5,i%5].axvline(np.median(all_vals0), color=color[0], linestyle=\"--\")\n",
    "    axs[i//5,i%5].hist(all_vals0, bins=np.linspace(0,4,40), alpha=0.5, color=color[0], density=True, label=\"full\")\n",
    "    if do_fim:\n",
    "        axs[i//5,i%5].axvline(np.median(all_vals1), color=color[1], linestyle=\"--\")\n",
    "        axs[i//5,i%5].hist(all_vals1, bins=np.linspace(0,4,40), alpha=0.5, color=color[1], density=True, label=\"fim\")\n",
    "    axs[i//5,i%5].set_title(f\"Seq. positions: ({keys[keys_t][0]}-{keys[keys_t][-1]})\")\n",
    "axs[0,0].legend()\n",
    "fig.supxlabel(\"Loss\")\n",
    "fig.supylabel(\"Count\")\n",
    "fig.suptitle(\"Loss distributions\")\n",
    "fig.savefig(f\"figures/{what}/loss_distributions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "if do_fim:\n",
    "    fig, axs = plt.subplots(2,5, figsize=(20,10), sharex=True, sharey=True, constrained_layout=True)\n",
    "    for i, keys_t in enumerate(list(keys.keys())):\n",
    "        all_vals0 = []\n",
    "        size_vals = []\n",
    "        for key in keys[keys_t]:\n",
    "            all_vals0 += dict_seq_fim_perp[key]\n",
    "            size_vals += dict_size_fim[key]\n",
    "        axs[i//5,i%5].plot(size_vals, all_vals0, \"o\", color=color[1], alpha=0.5)\n",
    "        axs[i//5,i%5].axhline(np.median(all_vals0), color=\"k\", linestyle=\"--\")\n",
    "        axs[i//5,i%5].axvline(np.median(size_vals), color=\"k\", linestyle=\"--\")\n",
    "        axs[i//5,i%5].set_title(f\"Seq. positions: ({keys[keys_t][0]}-{keys[keys_t][-1]})\")\n",
    "        axs[i//5,i%5].set_ylim(0,50)\n",
    "\n",
    "    fig.supxlabel(\"Size FIM masks (per sequence)\")\n",
    "    fig.supylabel(\"Perplexity\")\n",
    "    fig.savefig(f\"figures/{what}/fim_perplexity_vs_size.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lvec1 = [150, 250]\n",
    "dict_seq_perps, Lvec = split_lengths(dict_seq_perp, dict_seq_length, L=Lvec1)\n",
    "dict_seq_fim_perps, Lvec = split_lengths(dict_seq_fim_perp, dict_seq_fim_length, L=Lvec1)\n",
    "median_seq_perp = np.zeros(len(dict_seq_loss)+1)\n",
    "median_seq_loss, median_seq_perps = np.zeros(len(dict_seq_loss)+1), {ll: np.zeros(len(dict_seq_perps[ll])+1) for ll in Lvec}\n",
    "if do_fim:\n",
    "    median_seq_fim_loss, median_seq_fim_perp = np.zeros(max(dict_seq_fim_loss.keys())+1), {ll: np.zeros(max(dict_seq_fim_perps[ll].keys())+1) for ll in Lvec}\n",
    "for key in dict_seq_loss:\n",
    "    # avg_seq_loss[key] = np.mean(dict_seq_loss[key])\n",
    "    median_seq_loss[key] = np.median(dict_seq_loss[key])\n",
    "    median_seq_perp[key] = np.median(dict_seq_perp[key])\n",
    "    for ll in Lvec:\n",
    "        median_seq_perps[ll][key] = np.median(dict_seq_perps[ll][key])\n",
    "if do_fim:\n",
    "    for key in dict_seq_fim_loss:\n",
    "        median_seq_fim_loss[key] = np.median(dict_seq_fim_loss[key])\n",
    "        for ll in Lvec:\n",
    "            median_seq_fim_perp[ll][key] = np.median(dict_seq_fim_perps[ll][key])\n",
    "    \n",
    "fig, axs = plt.subplots(1,2, figsize=(20,5), constrained_layout=True)\n",
    "# inds = np.random.choice(len(dict_seq_loss), 1000)\n",
    "# for i in inds:\n",
    "#     el = dict_seq_loss[i], dict_seq_perps[i]\n",
    "#     axs[0].plot(np.ones_like(el[0])*i,el[0], \".\", color=color[0], alpha=0.05)\n",
    "#     axs[1].plot(np.ones_like(el[1])*i,el[1], \".\", color=color[0], alpha=0.05)\n",
    "# axs[0].plot(avg_seq_loss, \"k-\", label=\"Average\")\n",
    "axs[0].plot(smooth(median_seq_loss,0.6), \"k-\", label=\"Median\")\n",
    "# axs[1].plot(avg_seq_perp, \"k-\", label=\"Average\")\n",
    "# axs_new = axs[1].twinx()\n",
    "for i, ll in enumerate(Lvec):\n",
    "    if i==0:\n",
    "        string = f\"$0<L<${ll}\"\n",
    "    elif ll == Lvec[-1]:\n",
    "        string = f\"$L>${Lvec[-2]}\"\n",
    "    else:\n",
    "        string = f\"{Lvec[i-1]}$<L<${ll}\"\n",
    "    axs[1].plot(smooth(median_seq_perps[ll],0.8), \"-\", color=color[i+1], label=string)\n",
    "    axs[1].plot(smooth(median_seq_perp,0.8), \"--\", color=\"k\")\n",
    "    # axs_new.plot([len(dict_seq_perps[ll][key])/len(dict_seq_perps[ll][0]) for key in dict_seq_perps[ll].keys()], \"-\", color=color[0])\n",
    "axs[1].axhline(5, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "axs[1].axhline(10, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "# axs_new.set_ylabel(\"Fraction of clusters\", color=color[0])\n",
    "# axs_new.tick_params(axis='y', labelcolor=color[0])\n",
    "axs[0].set_ylim(top=4)\n",
    "# axs[1].set_ylim(0.1, 30)\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[1].set_ylabel(\"Perplexity\")\n",
    "# axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel(\"Number of sequences in context\")\n",
    "axs[1].set_xlabel(\"Number of sequences in context\")\n",
    "fig.savefig(f\"figures/{what}/seq_pos_perplexity_loss.pdf\", dpi=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_fim:\n",
    "    # dict_sizes_fim, Lvec = split_lengths(dict_size_fim, dict_seq_fim_length, L=Lvec1)\n",
    "    # median_seq_fim_loss_sz, median_seq_fim_perp_sz = {}, {}\n",
    "    # num_vals = {}\n",
    "    # median_seq_fim_perps_sz = {ll: {} for ll in Lvec}\n",
    "    # std_seq_fim_loss_sz, std_seq_fim_perp_sz = {}, {}\n",
    "    # sz_lst = [1,5,10,-10]\n",
    "    # for key in dict_seq_fim_loss:\n",
    "    #     sizes = dict_size_fim[key]\n",
    "    #     all_sizes = {ll: dict_sizes_fim[ll][key] for ll in Lvec}\n",
    "    #     for i,sz in enumerate(sz_lst):\n",
    "    #         if sz not in median_seq_fim_loss_sz:\n",
    "    #             median_seq_fim_loss_sz[sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #             median_seq_fim_perp_sz[sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #             num_vals[sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #             for ll in Lvec:\n",
    "    #                 median_seq_fim_perps_sz[ll][sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #             std_seq_fim_loss_sz[sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #             std_seq_fim_perp_sz[sz] = np.zeros(max(dict_seq_fim_loss.keys())+1)\n",
    "    #         if sz<0:\n",
    "    #             indxs = np.argwhere((np.array(sizes)-1) > -sz)[:,0]\n",
    "    #         else:\n",
    "    #             indxs = np.argwhere(((np.array(sizes)-1) <= sz) & ((np.array(sizes)-1) > (sz_lst[i-1] if i>0 else 0)))[:,0]\n",
    "    #         median_seq_fim_loss_sz[sz][key] = np.median([dict_seq_fim_loss[key][i] for i in indxs])\n",
    "    #         median_seq_fim_perp_sz[sz][key] = np.median([dict_seq_fim_perp[key][i] for i in indxs])\n",
    "    #         num_vals[sz][key] = len([dict_seq_fim_perp[key][i] for i in indxs])\n",
    "    #         for ll in Lvec:\n",
    "    #             if sz<0:\n",
    "    #                 all_indxs = np.argwhere((np.array(all_sizes[ll])-1) > -sz)[:,0]\n",
    "    #             else:\n",
    "    #                 all_indxs = np.argwhere(((np.array(all_sizes[ll])-1) <= sz) & ((np.array(all_sizes[ll])-1) > (sz_lst[i-1] if i>0 else 0)))[:,0]\n",
    "    #             median_seq_fim_perps_sz[ll][sz][key] = np.median([dict_seq_fim_perps[ll][key][i] for i in all_indxs])\n",
    "    #         std_seq_fim_loss_sz[sz][key] = np.std([dict_seq_fim_loss[key][i] for i in indxs])\n",
    "    #         std_seq_fim_perp_sz[sz][key] = np.std([dict_seq_fim_perp[key][i] for i in indxs])\n",
    "            \n",
    "    fig, axs = plt.subplots(1,1, figsize=(13,5), constrained_layout=True)\n",
    "\n",
    "    # moving_avg = lambda x, w: np.convolve(x, np.ones(w)/w, 'valid')\n",
    "    smoothing = 0.8\n",
    "    axs= [axs]\n",
    "    x_ticks = np.arange(len(median_seq_fim_loss))\n",
    "    x_ticks = x_ticks[median_seq_fim_loss>1e-10]\n",
    "    # axs[0].plot(x_ticks, smooth(median_seq_fim_perp[median_seq_fim_loss>1e-10],0.6), \"k-\", label=\"Median\")\n",
    "    for i, sz in enumerate(sz_lst):\n",
    "        str_sz = sz_lst[i-1] if i>0 else 0\n",
    "        lbl_name = f\"{str_sz} $ < N_m \\leq$ {sz}\" if sz>0 else f\"$N_m > $ {-sz}\"\n",
    "        lbl_name = f\"$N_m = $ {sz}\" if sz == 1 else lbl_name\n",
    "        where_vals = num_vals[sz][median_seq_fim_loss>1e-10]>0\n",
    "        axs[0].plot(x_ticks[where_vals], smooth(median_seq_fim_perp_sz[sz][median_seq_fim_loss>1e-10][where_vals], smoothing), label=lbl_name, color=color[i])\n",
    "        # for ll in Lvec:\n",
    "        #     axs[0].plot(x_ticks, smooth(median_seq_fim_perps_sz[ll][sz][median_seq_fim_loss>1e-10], smoothing), \"--\", color=color[i], alpha=0.5)\n",
    "        # axs[0].fill_between(x_ticks, smooth(median_seq_fim_perp_sz[sz][median_seq_fim_loss>1e-10]-std_seq_fim_perp_sz[sz][median_seq_fim_loss>1e-10], smoothing),\n",
    "        #                     smooth(median_seq_fim_perp_sz[sz][median_seq_fim_loss>1e-10]+std_seq_fim_perp_sz[sz][median_seq_fim_loss>1e-10], smoothing), alpha=0.3)\n",
    "\n",
    "    # axs[0].plot(x_ticks, smooth(median_seq_fim_perp[median_seq_fim_loss>1e-10],smoothing), \"k-\", label=\"All FIM\")\n",
    "    # axs[0].plot(smooth(median_seq_perp,smoothing), \"k--\", label=\"Full\")\n",
    "    # axs[0].axhline(5, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "    # axs[0].axhline(10, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "    # axs[0].set_ylim(2,11)\n",
    "    axs[0].set_xlim(left=-10)\n",
    "    axs[0].set_ylabel(\"Perplexity\")\n",
    "    axs[0].legend(frameon=False, loc=\"upper right\")\n",
    "    axs[0].set_xlabel(\"Number of sequences in context\")\n",
    "    fig.savefig(f\"figures/{what}/seq_pos_perplexity_fim.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(13,5), constrained_layout=True)\n",
    "\n",
    "smoothing = 0.0\n",
    "axs= [axs]\n",
    "x_ticks = np.arange(len(median_seq_fim_loss))\n",
    "x_ticks = x_ticks[median_seq_fim_loss>1e-10]\n",
    "# axs[0].plot(x_ticks, smooth(median_seq_fim_perp[median_seq_fim_loss>1e-10],0.6), \"k-\", label=\"Median\")\n",
    "for i, sz in enumerate(sz_lst):\n",
    "    str_sz = sz_lst[i-1] if i>0 else 0\n",
    "    lbl_name = f\"{str_sz} $ < N_m \\leq$ {sz}\" if sz>0 else f\"$N_m > $ {-sz}\"\n",
    "    lbl_name = f\"$N_m = $ {sz}\" if sz == 1 else lbl_name\n",
    "    axs[0].plot(x_ticks, num_vals[sz][median_seq_fim_loss>1e-10], label=lbl_name, color=color[i])\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_xlim(left=-10)\n",
    "axs[0].set_ylabel(\"Nvals\")\n",
    "axs[0].legend(frameon=False, loc=\"upper right\")\n",
    "axs[0].set_xlabel(\"Number of sequences in context\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_lengths = list(dict_ctx_lenghts.keys())\n",
    "dict_ctx_perps, Lvec = split_lengths(dict_ctx_perp, dict_ctx_len, Lvec1)\n",
    "dict_ctx_fim_perps, Lvec = split_lengths(dict_ctx_fim_perp, dict_ctx_fim_len, Lvec1)\n",
    "median_ctx_perp = {ll: np.zeros(len(ctx_lengths)) for ll in Lvec}\n",
    "median_ctx_fim_perp = {ll: np.zeros(len(ctx_lengths)) for ll in Lvec}\n",
    "median_ctx_lenghts = np.zeros(len(ctx_lengths))\n",
    "std_ctx_perp, std_ctx_fim_perp = np.zeros(len(ctx_lengths)), np.zeros(len(ctx_lengths))\n",
    "\n",
    "for i,key in enumerate(dict_ctx_perp):\n",
    "    for ll in Lvec:\n",
    "        median_ctx_perp[ll][i] = np.median(dict_ctx_perps[ll][key])\n",
    "        if do_fim:\n",
    "            median_ctx_fim_perp[ll][i] = np.median(dict_ctx_fim_perps[ll][key])\n",
    "    median_ctx_lenghts[i] = np.median(dict_ctx_lenghts[key])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(20,5), constrained_layout=True)\n",
    " \n",
    "for i, ll in enumerate(Lvec):\n",
    "    if i==0:\n",
    "        string = f\"$0<L<${ll}\"\n",
    "    elif ll == Lvec[-1]:\n",
    "        string = f\"$L>${Lvec[-2]}\"\n",
    "    else:\n",
    "        string = f\"{Lvec[i-1]}$<L<${ll}\"\n",
    "    axs[0].plot(median_ctx_lenghts, median_ctx_perp[ll], \"-\", color=color[i+1], label=string)\n",
    "    if do_fim:\n",
    "        axs[1].plot(median_ctx_lenghts, median_ctx_fim_perp[ll], \"-\", color=color[i+1], label=string)\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[1].set_xscale(\"log\")\n",
    "axs[0].set_xticks(ctx_lengths[:7]+[131072, 262144, 524288])\n",
    "axs[1].set_xticks(ctx_lengths[:7]+[131072, 262144, 524288])\n",
    "axs[0].set_xticklabels(ctx_lengths[:7]+[131072, 262144, 524288], rotation=45)\n",
    "axs[1].set_xticklabels(ctx_lengths[:7]+[131072, 262144, 524288], rotation=45)\n",
    "axs[0].set_ylabel(\"Perplexity full sequence\")\n",
    "axs[1].set_ylabel(\"Perplexity FIM tokens\")\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel(\"Number of tokens in context\")\n",
    "axs[1].set_xlabel(\"Number of tokens in context\")\n",
    "# fig.suptitle(\"Perplexity as function of context length\")\n",
    "fig.savefig(f\"figures/{what}/ctx_length_perplexity.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training logs and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 2048 - 70k steps\n",
    "print((64*2048*10**4+2*64*2048*6*10**4) / 10**10, \"10^10 tokens\")\n",
    "# training 16k - 164k steps\n",
    "print(8*2*16384*164000 /10**10, \"10^10 tokens\")\n",
    "# training 32k - 116k steps\n",
    "print(4*4*32768*118250 /10**10, \"10^10 tokens\")\n",
    "# training 131k - 8750 steps\n",
    "print(2*2*16*131072*8750 /10**10, \"10^10 tokens\")\n",
    "\n",
    "def interpolate(steps_array=np.linspace(10, 352000, 100), stops=[61000, 225000, 342100, -1], num_tokens=[64*2048*50,\n",
    "                                                                64*2048*10**4+2*64*2048*6*10**4,\n",
    "                                                                64*2048*10**4+2*64*2048*6*10**4+8*2*16384*164000,\n",
    "                                                                64*2048*10**4+2*64*2048*6*10**4+8*2*16384*164000+4*4*32768*118250,\n",
    "                                                                64*2048*10**4+2*64*2048*6*10**4+8*2*16384*164000+4*4*32768*118250+2*2*16*131072*8750,]):\n",
    "    tmp_length = 0\n",
    "    new_steps_array = np.zeros(len(steps_array))\n",
    "    if stops[-1] == -1:\n",
    "        stops[-1] = steps_array[-1]\n",
    "    for i in range(len(stops)):\n",
    "        length = sum(steps_array<=stops[i]) - tmp_length\n",
    "        if i == len(stops)-1:\n",
    "            length = len(steps_array) - tmp_length\n",
    "        new_steps_array[tmp_length:tmp_length+length] = np.linspace(num_tokens[i], num_tokens[i+1], length)\n",
    "        tmp_length += length\n",
    "        print(tmp_length, num_tokens[i], num_tokens[i+1])\n",
    "    return new_steps_array\n",
    "\n",
    "new = interpolate()\n",
    "new_logging = load_tensorboard_data(\"../../nbs/results/train_100M_FIM_restart-spikes_merged/merged-131072\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 0.5\n",
    "steps = np.array([el.step for el in new_logging['eval/train_loss/all']])\n",
    "steps = interpolate(steps)\n",
    "t_loss = np.array(smooth([el.value for el in new_logging['eval/train_loss/all']], smoothing))\n",
    "v_loss = np.array(smooth([el.value for el in new_logging['eval/valid_loss/all']], smoothing))\n",
    "t_perp = np.array(smooth([el.value for el in new_logging['eval/train_perplexity/batch']], smoothing))\n",
    "v_perp = np.array(smooth([el.value for el in new_logging['eval/valid_perplexity/batch']], smoothing))\n",
    "t_perp_fim = np.array(smooth([el.value for el in new_logging['eval/train_perplexity/fim']], smoothing))\n",
    "v_perp_fim = np.array(smooth([el.value for el in new_logging['eval/valid_perplexity/fim']], smoothing))\n",
    "\n",
    "# logarithmically spaced indices for plots with x axis in log scale\n",
    "idxs_log = np.unique([int(el)-1 for el in np.logspace(np.log10(1), np.log10(len(t_loss)), num = 4000)])\n",
    "# linearly spaced indices for plots with x axis in linear scale\n",
    "# idxs_log = np.linspace(0, len(t_loss)-1, 1000, dtype=int)\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(10,8), constrained_layout=True)\n",
    "\n",
    "axs[0].plot(steps[idxs_log],t_loss[idxs_log], color=color[0], label=\"Training\")\n",
    "axs[0].plot(steps[idxs_log],v_loss[idxs_log], color=color[2], label=\"Validation\")\n",
    "axs[1].plot(steps[idxs_log],t_perp[idxs_log], color=color[0])\n",
    "axs[1].plot(steps[idxs_log],v_perp[idxs_log], color=color[2])\n",
    "axs[2].plot(steps[idxs_log],t_perp_fim[idxs_log], color=color[0])\n",
    "axs[2].plot(steps[idxs_log],v_perp_fim[idxs_log], color=color[2])\n",
    "\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[1].set_xscale(\"log\")\n",
    "axs[1].set_ylabel(\"Perplexity\\nall tokens\")\n",
    "axs[2].set_xscale(\"log\")\n",
    "\n",
    "axs[2].set_ylabel(\"Perplexity\\nFIM tokens\")\n",
    "axs[2].set_xlabel(\"Training tokens\")\n",
    "axs[0].legend()\n",
    "fig.suptitle(\"Loss and Perplexity during training\")\n",
    "plt.show()\n",
    "fig.savefig(\"figures/training_loss_perplexity.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"figures/generated_sequences/dataframe_check-131k_gen_seqs_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
